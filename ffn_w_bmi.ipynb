{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the csv file and preprocess it: convert qualitative attributes to integers\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "# drop duplicates\n",
    "train = train.drop_duplicates()\n",
    "X = train.agg(utils.transform_dataset) # utils.transform_dataset is a dicitionary which applies a transforming function on each column\n",
    "y= X[\"Body_Level\"]\n",
    "y= y-1\n",
    "X = X.drop(\"Body_Level\", axis=1)\n",
    "X[\"BMI\"] = X[\"Weight\"].astype(float) / (X[\"Height\"] ** 2).astype(float)\n",
    "\n",
    "\n",
    "# Split the dataset into train and test sets\n",
    "# sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)\n",
    "\n",
    "# test to test and val\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=.2, random_state=42)\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Initialize the LazyClassifier and fit the training data\n",
    "sm = SMOTE(random_state=42)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Define the neural network architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, dropout=0):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(17, 32)\n",
    "        self.fc2 = nn.Linear(32, 64)\n",
    "        self.fc3 = nn.Linear(64, 32)\n",
    "        self.fc4 = nn.Linear(32, 15)\n",
    "        self.fc5 = nn.Linear(15, 4)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        # x= self.dropout(x)\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x= self.dropout(x)\n",
    "        x = torch.relu(self.fc3(x))\n",
    "        # x= self.dropout(x)\n",
    "        x = torch.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        # x = torch.softmax(x, dim=1)  # Apply the softmax function along the class dimension\n",
    "\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50,    68] loss: 0.004\n",
      "Accuracy of the network on the train data: 93.148\n",
      "Accuracy of the network on the val data: 98.305\n",
      "[100,    68] loss: 0.003\n",
      "Accuracy of the network on the train data: 93.657\n",
      "Accuracy of the network on the val data: 94.915\n",
      "[150,    68] loss: 0.001\n",
      "Accuracy of the network on the train data: 97.407\n",
      "Accuracy of the network on the val data: 100.000\n",
      "[200,    68] loss: 0.002\n",
      "Accuracy of the network on the train data: 95.417\n",
      "Accuracy of the network on the val data: 96.610\n",
      "[250,    68] loss: 0.002\n",
      "Accuracy of the network on the train data: 87.361\n",
      "Accuracy of the network on the val data: 93.220\n",
      "[300,    68] loss: 0.002\n",
      "Accuracy of the network on the train data: 99.352\n",
      "Accuracy of the network on the val data: 96.610\n",
      "[350,    68] loss: 0.002\n",
      "Accuracy of the network on the train data: 99.306\n",
      "Accuracy of the network on the val data: 98.305\n",
      "[400,    68] loss: 0.001\n",
      "Accuracy of the network on the train data: 99.120\n",
      "Accuracy of the network on the val data: 96.610\n",
      "[450,    68] loss: 0.001\n",
      "Accuracy of the network on the train data: 99.491\n",
      "Accuracy of the network on the val data: 98.305\n",
      "[500,    68] loss: 0.002\n",
      "Accuracy of the network on the train data: 99.120\n",
      "Accuracy of the network on the val data: 100.000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train_tensor = torch.from_numpy(X_train.values).float()\n",
    "X_test_tensor = torch.from_numpy(X_test.values).float()\n",
    "X_val_tensor = torch.from_numpy(X_val.values).float()\n",
    "\n",
    "y_train_tensor = torch.from_numpy(y_train.values).long()\n",
    "y_test_tensor = torch.from_numpy(y_test.values).long()\n",
    "y_val_tensor = torch.from_numpy(y_val.values).long()\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "net = Net(dropout=0.2)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.001, weight_decay=0.001)\n",
    "\n",
    "# Train the neural network with L2 regularization\n",
    "count =0\n",
    "model_fin = None\n",
    "last_val_acc = 0\n",
    "for epoch in range(500):\n",
    "    running_loss = 0.0\n",
    "    count +=1\n",
    "    for i, data in enumerate(train_loader, 0):\n",
    "        # Get the inputs\n",
    "        inputs, labels = data\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print statistics\n",
    "        running_loss += loss.item()\n",
    "    if count % 50 == 0:    # print every 2000 mini-batches\n",
    "        print('[%d, %5d] loss: %.3f' %\n",
    "                (epoch + 1, i + 1, running_loss / 2000))\n",
    "        running_loss = 0.0\n",
    "        # print acc\n",
    "        with torch.no_grad():\n",
    "            outputs = net(X_train_tensor)\n",
    "            _, predicted_train = torch.max(outputs.data, 1)\n",
    "        print('Accuracy of the network on the train data: %.3f' % (100 * torch.sum(y_train_tensor == predicted_train) / len(y_train_tensor)))\n",
    "        # get val\n",
    "        with torch.no_grad():\n",
    "            outputs = net(X_val_tensor)\n",
    "            _, predicted_val = torch.max(outputs.data, 1)\n",
    "        val_acc= 100 * torch.sum(y_val_tensor == predicted_val) / len(y_val_tensor)\n",
    "        if (val_acc >= last_val_acc) :\n",
    "            last_val_acc = val_acc\n",
    "            model_fin = net\n",
    "        print('Accuracy of the network on the val data: %.3f' % (100 * torch.sum(y_val_tensor == predicted_val) / len(y_val_tensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the test data: 97.863\n",
      "F1 score of the network on the test data: 0.979\n",
      "Accuracy of the network on the train data: 98.981\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "#get acc test\n",
    "with torch.no_grad():\n",
    "    outputs = model_fin(X_test_tensor)\n",
    "    _, predicted_test = torch.max(outputs.data, 1)\n",
    "# print acc\n",
    "print('Accuracy of the network on the test data: %.3f' % (100 * torch.sum(y_test_tensor == predicted_test) / len(y_test_tensor)))\n",
    "# get f1\n",
    "print('F1 score of the network on the test data: %.3f' % (f1_score(y_test_tensor, predicted_test, average='macro')))\n",
    "\n",
    "\n",
    "# get acc train\n",
    "with torch.no_grad():\n",
    "    outputs = model_fin(X_train_tensor)\n",
    "    _, predicted_train = torch.max(outputs.data, 1)\n",
    "# print acc\n",
    "print('Accuracy of the network on the train data: %.3f' % (100 * torch.sum(y_train_tensor == predicted_train) / len(y_train_tensor)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=17, out_features=32, bias=True)\n",
       "  (fc2): Linear(in_features=32, out_features=64, bias=True)\n",
       "  (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
       "  (fc4): Linear(in_features=32, out_features=15, bias=True)\n",
       "  (fc5): Linear(in_features=15, out_features=4, bias=True)\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fin.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "torch.save(model_fin.state_dict(), \"ffn_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
